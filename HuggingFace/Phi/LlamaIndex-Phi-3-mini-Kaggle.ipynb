{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -qqq install llama-index llama-index-llms-huggingface flash-attn --progress-bar off","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-20T03:11:32.277124Z","iopub.execute_input":"2024-06-20T03:11:32.277728Z","iopub.status.idle":"2024-06-20T03:12:12.078849Z","shell.execute_reply.started":"2024-06-20T03:11:32.277687Z","shell.execute_reply":"2024-06-20T03:12:12.077718Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"HF_TOKEN = str(\"Enter HuggingFace API Key\")","metadata":{"execution":{"iopub.status.busy":"2024-06-20T03:17:16.336554Z","iopub.execute_input":"2024-06-20T03:17:16.336932Z","iopub.status.idle":"2024-06-20T03:17:16.341642Z","shell.execute_reply.started":"2024-06-20T03:17:16.336904Z","shell.execute_reply":"2024-06-20T03:17:16.340482Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from llama_index.llms.huggingface import HuggingFaceLLM\nfrom IPython.display import Markdown\n\n\ndef messages_to_prompt(messages):\n    prompt = \"\"\n    system_found = False\n    for message in messages:\n        if message.role == \"system\":\n            prompt += f\"<|system|>\\n{message.content}<|end|>\\n\"\n            system_found = True\n        elif message.role == \"user\":\n            prompt += f\"<|user|>\\n{message.content}<|end|>\\n\"\n        elif message.role == \"assistant\":\n            prompt += f\"<|assistant|>\\n{message.content}<|end|>\\n\"\n        else:\n            prompt += f\"<|user|>\\n{message.content}<|end|>\\n\"\n\n    # trailing prompt\n    prompt += \"<|assistant|>\\n\"\n\n    if not system_found:\n        prompt = (\n            \"<|system|>\\nYou are a helpful AI assistant.<|end|>\\n\" + prompt\n        )\n\n    return prompt\n\n\nllm = HuggingFaceLLM(\n    model_name=\"microsoft/Phi-3-mini-4k-instruct\",\n    model_kwargs={\n        \"trust_remote_code\": True\n    },\n    generate_kwargs={\"do_sample\": True, \"temperature\": 0.1},\n    tokenizer_name=\"microsoft/Phi-3-mini-4k-instruct\",\n    query_wrapper_prompt=(\n        \"<|system|>\\n\"\n        \"You are a helpful AI assistant.<|end|>\\n\"\n        \"<|user|>\\n\"\n        \"{query_str}<|end|>\\n\"\n        \"<|assistant|>\\n\"\n    ),\n    messages_to_prompt=messages_to_prompt,\n    is_chat_model=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T03:12:12.087155Z","iopub.execute_input":"2024-06-20T03:12:12.087519Z","iopub.status.idle":"2024-06-20T03:13:04.781801Z","shell.execute_reply.started":"2024-06-20T03:12:12.087487Z","shell.execute_reply":"2024-06-20T03:13:04.780557Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n\nYou may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/931 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd18eec819494cd68ba65c009b432def"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec57962918074dc5a749be89840c53f5"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3f68df61e24447b69129c1b7314055"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b84509d2ee34851a6b2f9d8f380f7f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a85edff91624bc98da13ca9df6657dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a4f29ba593e4491a521d06da42e9f12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc901aa418134efaaf6a6fdd62780427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20bbb692e2df41679321aae764714bdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01fbbeee45cb4961a4bf6562900c36ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d9107814574f7b963d40c6251f96e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"638cfb3cab1e4c80a3febc1cf5aae2c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea4a0fa7a98b4dc9bfb2023a04daa24c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8966820377054d19a43b446cc7267509"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40c155e9124a4711810e269d1f87ad2d"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"user_prompt = \"Write a paragraph about Nikola Tesla and wireless electricity.\"\nresponse = llm.complete(user_prompt)\nMarkdown(response.text)","metadata":{"execution":{"iopub.status.busy":"2024-06-20T03:15:24.657946Z","iopub.execute_input":"2024-06-20T03:15:24.658642Z","iopub.status.idle":"2024-06-20T03:16:26.349793Z","shell.execute_reply.started":"2024-06-20T03:15:24.658611Z","shell.execute_reply":"2024-06-20T03:16:26.348896Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Nikola Tesla, a Serbian-American inventor, electrical engineer, mechanical engineer, and futurist, is widely recognized for his groundbreaking contributions to the development of alternating current (AC) electrical systems. However, one of his most revolutionary ideas was the concept of wireless electricity, which he envisioned as a means to transmit electrical power without the need for wires. Tesla's visionary concept of wireless electricity, also known as \"Tesla's Wireless Power,\" was first introduced in the late 19th century. He believed that it was possible to transmit electrical energy through the Earth's atmosphere and even through space, using resonant inductive coupling. Tesla's experiments with wireless transmission of electricity led to the creation of the Wardenclyffe Tower, a massive structure designed to demonstrate the feasibility of wireless power transmission. Although Tesla's ambitious project was ultimately abandoned due to financial difficulties, his pioneering work laid the foundation for modern wireless charging technologies and continues to inspire researchers and innovators in the field of wireless power transmission."},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}